spark run code:
${SPARK_HOME}/bin/spark-submit newplayer_prepare.py player_info.csv etl_player_summary_output input_summary

python run code:
python new_player_analysis.py input_summary players.txt "Orlando Johnson" output

players.txt have 100 top players information: https://www.si.com/nba/2020/12/14/top-100-nba-players-2021-daily-cover
sys.argv[3]:for example: "Orlando Johnson" taken from new_player.txt(contains all the "new" players who were drafted less or equal two years)
output contains all the png 

png by order
1： draft_year.png: shows that, in 2020, distributions of the players'drafted year. Since the undrafted_year accounts for over 20%, we would like to replace "Undrafted" string with reasonable number rather than delete them 
2： position.png: shows the distributions of players for each positions from 2010 to 2020. Since there is not very large gap exist, our data can be classified according to positions
3： number_of_year.png: shows the distributions of players's drafted year from 2010 to 2020 
### note that the 1 and 3 kind of similar


4： position_distrution_png: this is how our data classified by player_position and top-100 players' name was labeled on it.
5: new_player_distribution_png: this is top-100 players distribution classified by position
6: result.png: new_player is Oriando Johnson for example. new_player was marked by "X" and other top-100 players were marked by "o".
               from this result, we can see that Joe Harris's performance is the closest approximation to out new_players under the same position.
               different positions were marked by different colors which showed by legend.
               this result matched our calculation of min-distance which printed on the run_python_output.png


